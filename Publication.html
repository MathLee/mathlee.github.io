<html>
<head>
<title>GONGYANG LI</title>
<style>
h1 { padding : 0; margin : 0; }
body { padding : 0; font-family : Arial; font-size : 16px;  background-color : #EFEFEF;} /* background-image : url('bg.png');}*/
#container { width : 900px; margin : 20px auto; border-radius: 15px;  background-color : #fff; padding : 50px;  box-shadow: 0px 0px 10px #999; } /* border : 1px solid #ccc; } */
#me { border : 0 solid black; margin-bottom : 50px;}
#sidebar { margin-left : 25px; border : 0 solid black; float : right; margin-bottom : 0;}
#content { display : block; }
a { text-decoration : none; }
a:hover { text-decoration : underline; }
a, a:visited { color : #0050e7; }
a.invisible { color : inherit; text-decoration : inherit; }
.publogo { margin-right : 20px; float : left; border : 0;}
.publication { clear : left; padding-bottom : 0px; }
.publication p { height : 100px; padding-top : 5px;}
.publication strong a { color : #000; }
.publication .links { position : relative; top : 15px }
.publication .links a { margin-right : 20px; }
.codelogo { margin-right : 10px; float : left; border : 0;}
.code { clear : left; padding-bottom : 10px; vertical-align :middle;} 
.code .download a { display : block; margin : 0 15px; float : left;}
.code strong a { color : #000; }
#simpsons { margin : 5px auto; text-align : left; color : #B7B7B7; }
#erdos { color : #999; text-align : center; font-size : 12px; }
.contact { margin-left : 40px; }
.contact td { width : 300px; vertical-align : top; }
.schoollogo { text-align : center; color : #999; width : 150px;}
.schoollogo img { margin-bottom : 10px; }
</style>

<script type="text/javascript">

var _gaq = _gaq || [];
_gaq.push(['_setAccount', 'UA-17813713-3']);
_gaq.push(['_setDomainName', '.mit.edu']);
_gaq.push(['_trackPageview']);

(function() {
var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})();

</script>


<body>
<div id="container">
<div id="content">

<h3>
[<a href="https://mathlee.github.io/" style="color:#58ACFA">Main</a>]
[<a href="https://mathlee.github.io/Publication.html">Publication</a>]
[<a href="https://scholar.google.com/citations?hl=zh-CN&user=YNq7jc8AAAAJ" target="blank" style="color:#58ACFA">Google Scholar</a>]
[<a href="https://github.com/mathlee" target="blank" style="color:#58ACFA">Code & Data</a>]
</h3>

	
<!-- <h3><div style="color:#58ACFA">Accepted</h3> -->
<h3 style="border-bottom: 2px solid; font-size: 22px; color:#58ACFA">Accepted</h3></p>

<div class="publication">
<strong>
RGB-T Semantic Segmentation with Location, Activation, and Sharpening
</strong>
<br>
<b>Gongyang Li</b>, Yike Wang, Zhi Liu, Xinpeng Zhang, Dan Zeng
</br>
<em>IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>)</em>, 2022.
<br>
<a href="https://ieeexplore.ieee.org/document/9900351">[Paper]</a>
<a href="https://github.com/MathLee/LASNet">[Github]</a>
</div>

<br></br>
	
<div class="publication">
<strong>
Adjacent Context Coordination Network for Salient Object Detection in Optical Remote Sensing Images
</strong>
<br>
<b>Gongyang Li</b>, Zhi Liu, Dan Zeng, Weisi Lin, Haibin Ling
</br>
<em>IEEE Transactions on Cybernetics (<b>TCYB</b>)</em>, 2022.
<br>
<a href="https://ieeexplore.ieee.org/document/9756652">[Paper]</a>
<a href="https://arxiv.org/abs/2203.13664">[Arxiv]</a>
<a href="https://github.com/MathLee/ACCoNet">[Github]</a>
</div>


<br></br>
	
<div class="publication">
<strong>
Spatio-Temporal Self-Attention Network for Video Saliency Prediction
</strong>
<br>
Ziqiang Wang, Zhi Liu, <b>Gongyang Li</b>, Yang Wang, Tianhong Zhang, Lihua Xu, Jijun Wang
</br>
<em>IEEE Transactions on Multimedia (<b>TMM</b>)</em>, 2021.
<br>
<a href="https://ieeexplore.ieee.org/document/9667292">[Paper]</a>
<a href="https://arxiv.org/abs/2108.10696">[Arxiv]</a>
<!-- <a href="https://github.com/MathLee/MCCNet">[Github]</a> -->
</div>


<br></br>

<div class="publication">
<strong>
Adaptive Group-wise Consistency Network for Co-saliency Detection
</strong>
<br>
Zhen Bai, Zhi Liu, <b>Gongyang Li</b>, Yang Wang
</br>
<em>IEEE Transactions on Multimedia (<b>TMM</b>)</em>, 2021.
<br>
<a href="https://ieeexplore.ieee.org/document/9662960">[Paper]</a>
<!--<a href="https://arxiv.org/abs/2112.01932">[Arxiv]</a>-->
<a href="https://github.com/bz536476/AGCNet">[Github]</a>
</div>
		
<!-- <h3><div style="color:#58ACFA">2022</h3> -->
<h3 style="border-bottom: 2px solid; font-size: 22px; color:#58ACFA">2022</h3></p>	
	

<div class="publication">
<strong>
Two-Stage Edge Reuse Network for Salient Object Detection of Strip Steel Surface Defects
</strong>
<br>
Chengjun Han#, <b>Gongyang Li#</b>, Zhi Liu (# equal contribution)
</br>
<em>IEEE Transactions on Instrumentation and Measurement (<b>TIM</b>)</em>, vol. 71, Art no. 5019812, 2022.
<br>
<a href="https://ieeexplore.ieee.org/document/9862999">[Paper]</a>
<a href="https://github.com/monxxcn/TSERNet">[Github]</a>
</div>

<br></br>


<div class="publication">
<strong>
Gaze Estimation via Modulation-based Adaptive Network with Auxiliary Self-Learning
</strong>
<br>
Yong Wu#, <b>Gongyang Li#</b>, Zhi Liu, Mengke Huang, Yang Wang (# equal contribution)
</br>
<em>IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>)</em>, vol. 32, no. 8, pp. 5510-5520, 2022.
<br>
<a href="https://ieeexplore.ieee.org/document/9717236">[Paper]</a>
<!-- <a href="https://arxiv.org/abs/2201.08049">[Arxiv]</a>
<a href="https://github.com/MathLee/CorrNet">[Github]</a> -->
</div>

<br></br>

<div class="publication">
<strong>
Cross-Scale Edge Purification Network for Salient Object Detection of Steel Defect Images
</strong>
<br>
Tuo Ding#, <b>Gongyang Li#</b>, Zhi Liu, Yike Wang (# equal contribution)
</br>
<em>Measurement</em>, vol. 199, Art no. 111429, 2022.
<br>
<a href="https://www.sciencedirect.com/science/article/pii/S0263224122006595?via%3Dihub">[Paper]</a>
<a href="https://github.com/showmaker369/CSEPNet">[Github]</a>
</div>

<br></br>

<div class="publication">
<strong>
Lightweight Salient Object Detection in Optical Remote Sensing Images via Feature Correlation
</strong>
<br>
<b>Gongyang Li</b>, Zhi Liu, Zhen Bai, Weisi Lin, Haibin Ling
</br>
<em>IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>)</em>, vol. 60, Art no. 5617712, 2022.
<br>
<a href="https://ieeexplore.ieee.org/document/9690514">[Paper]</a>
<a href="https://arxiv.org/abs/2201.08049">[Arxiv]</a>
<a href="https://github.com/MathLee/CorrNet">[Github]</a>
</div>

<br></br>

<div class="publication">
<strong>
Multi-Content Complementation Network for Salient Object Detection in Optical Remote Sensing Images
</strong>
<br>
<b>Gongyang Li</b>, Zhi Liu, Weisi Lin, Haibin Ling
</br>
<em>IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>)</em>, vol. 60, Art no. 5614513, 2022.
<br>
<a href="https://ieeexplore.ieee.org/document/9631225">[Paper]</a>
<a href="https://arxiv.org/abs/2112.01932">[Arxiv]</a>
<a href="https://github.com/MathLee/MCCNet">[Github]</a>
</div>


<!-- <h3><div style="color:#58ACFA">2021</h3> -->
<h3 style="border-bottom: 2px solid; font-size: 22px; color:#58ACFA">2021</h3></p>
	
<div class="publication">
<strong>
Hierarchical Alternate Interaction Network for RGB-D Salient Object Detection
</strong>
<br>
<b>Gongyang Li</b>, Zhi Liu, Minyu Chen, Zhen Bai, Weisi Lin, Haibin Ling
</br>
<em>IEEE Transactions on Image Processing (<b>TIP</b>)</em>, vol. 30, pp. 3528-3542, 2021.
<br>
<a href="https://ieeexplore.ieee.org/document/9371407">[Paper]</a>
<a href="https://github.com/MathLee/HAINet">[Github]</a>
</div>

<br></br>

<div class="publication">
<strong>
Personal Fixations-based Object Segmentation with Object Localization and Boundary Preservation
</strong>
<br>
<b>Gongyang Li</b>, Zhi Liu, Ran Shi, Zheng Hu, Weijie Wei, Yong Wu, Mengke Huang, Haibin Ling
</br>
<em>IEEE Transactions on Image Processing (<b>TIP</b>)</em>, vol. 30, pp. 1461-1475, 2021.
<br>
<a href="https://ieeexplore.ieee.org/document/9298925">[Paper]</a>
<a href="https://arxiv.org/abs/2101.09014">[Arxiv]</a>
<a href="https://github.com/MathLee/OLBPNet4PFOS">[Github]</a>
</div>

<br></br>

<div class="publication">
<strong>
Circular Complement Network for RGB-D Salient Object Detection
</strong>
<br>
Zhen Bai, Zhi Liu, <b>Gongyang Li</b>, Linwei Ye, Yang Wang
</br>
<em>Neurocomputing</em>, vol. 451, pp. 95-106, 2021.
<br>
<a href="https://www.sciencedirect.com/science/article/pii/S0925231221005944">[Paper]</a>
<a href="https://github.com/bz536476/CCNet">[Github]</a>
</div>

<br></br>

<div class="publication">
<strong>
Personalized Image Observation Behavior Learning in Fixation based Personalized Salient Object Segmentation
</strong>
<br>
Ran Shi, <b>Gongyang Li</b>, Weijie Wei, Xiaofei Zhou, Zhi Liu
</br>
<em>Neurocomputing</em>, vol. 445, pp. 255-266, 2021.
<br>
<a href="https://www.sciencedirect.com/science/article/pii/S0925231221004100">[Paper]</a>
</div>

<br></br>

<div class="publication">
<strong>
Fixations based Personal Target Objects Segmentation
</strong>
<br>
Ran Shi, <b>Gongyang Li</b>, Weijie Wei, Zhi Liu
</br>
<em>ACM International Conference on Multimedia in Asia (<b>MMAsia 2020</b>)</em>, Singapore, Mar. 2021.
<br>
<a href="https://dl.acm.org/doi/pdf/10.1145/3444685.3446310">[Paper]</a>
</br>
</div>


<!-- <h3><div style="color:#58ACFA">2020</h3> -->
<h3 style="border-bottom: 2px solid; font-size: 22px; color:#58ACFA">2020</h3></p>
	
<div class="publication">
<strong>
ICNet: Information Conversion Network for RGB-D based Salient Object Detection
</strong>
<br>
<b>Gongyang Li</b>, Zhi Liu, Haibin Ling
</br>
<em>IEEE Transactions on Image Processing (<b>TIP</b>)</em>, vol. 29, pp. 4873-4884, 2020. <strong><font color="#FF5151"><i>ESI Highly Cited Paper</i></font></strong>
<br>
<a href="https://ieeexplore.ieee.org/document/9024241">[Paper]</a>
<a href="https://github.com/MathLee/ICNet-for-RGBD-SOD">[Github]</a>
</div>

<br></br>

<div class="publication">
<strong>
Cross-Modal Weighting Network for RGB-D Salient Object Detection
</strong>
<br>
<b>Gongyang Li</b>, Zhi Liu, Linwei Ye, Yang Wang, Haibin Ling
</br>
<em>European Conference on Computer Vision (<b>ECCV</b>)</em>, pp. 665-681, Glasgow, UK, Aug. 2020.
<br>
<a href="https://link.springer.com/chapter/10.1007/978-3-030-58520-4_39">[Paper]</a>
<a href="https://arxiv.org/abs/2007.04901">[Arxiv]</a>
<a href="https://github.com/MathLee/CMWNet">[Github]</a>
</div>
	
<br></br>

<div class="publication">
<strong>
Attention-guided RGBD Saliency Detection using Appearance Information
</strong>
<br>
Xiaofei Zhou, <b>Gongyang Li</b>, Chen Gong, Zhi Liu, Jiyong Zhang
</br>
<em>Image and Vision Computing (<b>IVC</b>)</em>, vol. 95, 103888, 2020.
<br>
<a href="https://www.sciencedirect.com/science/article/pii/S0262885620300202">[Paper]</a>
</br>
</div>

<br></br>

<div class="publication">
<strong>
FANet: Features Adaptation Network for 360Â° Omnidirectional Salient Object Detection
</strong>
<br>
Mengke Huang, Zhi Liu, <b>Gongyang Li</b>, Xiaofei Zhou, Olivier Le Meur
</br>
<em>IEEE Signal Processing Letters (<b>SPL</b>)</em>, vol. 27, pp. 1819-1823, 2020.
<br>
<a href="https://ieeexplore.ieee.org/document/9211754">[Paper]</a>
<a href="https://github.com/DreaMKHuang/FANet">[Github]</a>
</br>
</div>

<br></br>

<div class="publication">
<strong>
Weakly Supervised Instance Segmentation using Multi-stage Erasing Refinement and Saliency-guided Proposals Ordering
</strong>
<br>
Zheng Hu, Zhi Liu, <b>Gongyang Li</b>, Linwei Ye, Lei Zhou, Yang Wang
</br>
<em>Journal of Visual Communication and Image Representation (<b>JVCI</b>)</em>, vol. 73, Art no. 102957, 2020.
<br>
<a href="https://www.sciencedirect.com/science/article/pii/S104732032030184X">[Paper]</a>
<a href="https://github.com/jetshz/MSER-SGPO">[Github]</a>
</br>
</div>

<br></br>

<div class="publication">
<strong>
Co-Saliency Detection using Collaborative Feature Extraction and High-to-Low Feature Integration
</strong>
<br>
Jingru Ren, Zhi Liu, <b>Gongyang Li</b>, Xiaofei Zhou, Cong Bai, Guangling Sun
</br>
<em>IEEE International Conference on Multimedia and Expo (<b>ICME</b>)</em>, London, UK, Jul. 2020.
<br>
<a href="https://ieeexplore.ieee.org/document/9102969">[Paper]</a>
<a href="https://pan.baidu.com/share/init?surl=RofTzQ07Vi-GRohnmSy7pg">[Results (code: 180w)]</a>
</br>
</div>

<br></br>

<div class="publication">
<strong>
Fine-grained Image Classification with Coarse and Fine Labels on One-shot Learning
</strong>
<br>
Qihan Jiao, Zhi Liu, <b>Gongyang Li</b>, Linwei Ye, Yang Wang
</br>
<em>IEEE International Conference on Multimedia and Expo Workshops (<b>ICMEW</b>)</em>, London, UK, Jul. 2020.
<br>
<a href="https://ieeexplore.ieee.org/document/9105959">[Paper]</a>
<a href="https://pan.baidu.com/share/init?surl=8j5sa8WITcRzWDoSathT8g">[Results (code: mkY7)]</a>
</br>
</div>


<!-- <h3><div style="color:#58ACFA">2019 and Before</h3> -->
<h3 style="border-bottom: 2px solid; font-size: 22px; color:#58ACFA">2019 and Before</h3></p>

<div class="publication">
<strong>
Constrained Fixation Point based Segmentation via Deep Neural Network
</strong>
<br>
<b>Gongyang Li</b>, Zhi Liu, Ran Shi, Weijie Wei
</br>
<em>Neurocomputing</em>, vol. 368, pp. 180-187, 2019.
<br>
<a href="https://www.sciencedirect.com/science/article/pii/S0925231219311890">[Paper]</a>
<a href="https://github.com/MathLee/CFPS">[Github]</a>
</br>
</div>

<br></br>

<div class="publication">
<strong>
Effective Online Refinement for Video Object Segmentation
</strong>
<br>
<b>Gongyang Li</b>, Zhi Liu, Xiaofei Zhou
</br>
<em>Multimedia Tools and Applications (<b>MTAP</b>)</em>, vol. 78, pp. 33617-33631, 2019.
<br>
<a href="https://link.springer.com/article/10.1007/s11042-019-08146-3">[Paper]</a>
<a href="https://github.com/MathLee/EOR-VOS">[Github]</a>
</br>
</div>

<br></br>

<div class="publication">
<strong>
Video Saliency Detection using Deep Convolutional Neural Networks
</strong>
<br>
Xiaofei Zhou, Zhi Liu, Chen Gong, <b>Gongyang Li</b>, Mengke Huang
</br>
<em>Chinese Conference on Pattern Recognition on Computer Vision (<b>PRCV</b>)</em>, pp. 308-319, Guangzhou, China, Nov. 2018.
<br>
<a href="https://link.springer.com/chapter/10.1007%2F978-3-030-03335-4_27">[Paper]</a>
</br>
</div>

<br></br>



<!--<p style="text-align:center;font-size:16px;padding-top:20px;">All things are difficult before they are easy.-->
<!--<br>&mdash; Thomas Fuller</p>-->

<br clear="both">
<br>
<br>
<br>
<br>
<br>
<br>
<button type="button"><span id="scrolltop" onclick="window.scrollTo(&#39;0&#39;,&#39;0&#39;)">Back to TOP</span></button>

</div>
</div>

</body>
</html>

