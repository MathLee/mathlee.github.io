<html>
<head>
<title>GONGYANG LI</title>
<style>
h1 { padding : 0; margin : 0; }
body { padding : 0; font-family : Arial; font-size : 16px;  background-color : #EFEFEF;} /* background-image : url('bg.png');}*/
#container { width : 900px; margin : 20px auto; border-radius: 15px;  background-color : #fff; padding : 50px;  box-shadow: 0px 0px 10px #999; } /* border : 1px solid #ccc; } */
#me { border : 0 solid black; margin-bottom : 50px;}
#sidebar { margin-left : 25px; border : 0 solid black; float : right; margin-bottom : 0;}
#content { display : block; }
a { text-decoration : none; }
a:hover { text-decoration : underline; }
a, a:visited { color : #0050e7; }
a.invisible { color : inherit; text-decoration : inherit; }
.publogo { margin-right : 20px; float : left; border : 0;}
.publication { clear : left; padding-bottom : 0px; }
.publication p { height : 100px; padding-top : 5px;}
.publication strong a { color : #000; }
.publication .links { position : relative; top : 15px }
.publication .links a { margin-right : 20px; }
.codelogo { margin-right : 10px; float : left; border : 0;}
.code { clear : left; padding-bottom : 10px; vertical-align :middle;} 
.code .download a { display : block; margin : 0 15px; float : left;}
.code strong a { color : #000; }
#simpsons { margin : 5px auto; text-align : left; color : #B7B7B7; }
#erdos { color : #999; text-align : center; font-size : 12px; }
.contact { margin-left : 40px; }
.contact td { width : 300px; vertical-align : top; }
.schoollogo { text-align : center; color : #999; width : 150px;}
.schoollogo img { margin-bottom : 10px; }
</style>

<script type="text/javascript">

var _gaq = _gaq || [];
_gaq.push(['_setAccount', 'UA-17813713-3']);
_gaq.push(['_setDomainName', '.mit.edu']);
_gaq.push(['_trackPageview']);

(function() {
var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})();

</script>


<body>
<div id="container">
<div id="content">

<h3>
[<a href="https://mathlee.github.io/" style="color:#58ACFA">Main</a>]
[<a href="https://mathlee.github.io/Publication.html">Publication</a>]
[<a href="https://mathlee.github.io/Group.html" style="color:#58ACFA">Group</a>]
[<a href="https://scholar.google.com/citations?hl=zh-CN&user=YNq7jc8AAAAJ" target="blank" style="color:#58ACFA">Google Scholar</a>]
[<a href="https://github.com/mathlee" target="blank" style="color:#58ACFA">Code & Data</a>]
</h3>

	
<!-- <h3><div style="color:#58ACFA">Accepted</h3> -->
<h3 style="border-bottom: 2px solid; font-size: 22px; color:#58ACFA">Accepted</h3></p>

<div class="publication">
<strong>
Query-Focused Video Summarization Driven by Sentences
</strong>
<br>
Kaifan Zhao, Ran Ma, Haozhe Yu, Ping An, <b>Gongyang Li</b>
</br>
<em>Displays</em>, 2026.
<br>
<!-- <a href="./PDF/xxx.pdf">[PDF]</a> -->
<!-- <a href="https://ieeexplore.ieee.org/document/xxx">[PaperLink]</a> -->
<!-- <a href="https://github.com/xx">[Code]</a> -->
</div>

<br></br>
	
<div class="publication">
<strong>
Few-shot Strip Steel Surface Defect Segmentation via pre-trained Variational Auto-Encoder based Latent Gaussian Process Regression
</strong>
<br>
Xiaofei Zhou, Xuan Wang, <b>Gongyang Li</b>, Deyang Liu, Qingshan She, Xiaobin Xu, Runmin Cong
</br>
<em>IEEE Transactions on Image Processing (<b>TIP</b>)</em>, 2025.
<br>
<!-- <a href="./PDF/xxx.pdf">[PDF]</a> -->
<!-- <a href="https://ieeexplore.ieee.org/document/xxx">[PaperLink]</a> -->
<!-- <a href="https://github.com/xx">[Code]</a> -->
</div>

<br></br>


	
<div class="publication">
<strong>
STENet: Superpixel Token Enhancing Network for RGB-D Salient Object Detection
</strong>
<br>
Jianlin Chen, <b>Gongyang Li*</b>, Zhijiang Zhang*, Liang Chang, Dan Zeng (* corresponding author)
</br>
<em>IEEE Transactions on Multimedia (<b>TMM</b>)</em>, 2025.
<br>
<a href="./PDF/2026_TMM_Jianlin.pdf">[PDF]</a>
<!-- <a href="https://ieeexplore.ieee.org/document/xxx">[PaperLink]</a> -->
<a href="https://github.com/Mark9010/STENet">[Code]</a>
</div>

<br></br>

<div class="publication">
<strong>
基于扩散模型的注意力驱动RGB-D显著性目标检测
</strong>
<br>
<b>李恭杨</b>, 史世翔, 李红云
</br>
<em>信号处理</em>, 2025.
<br>
<!-- <a href="./PDF/2024_TNNLS_Yingjie.pdf">[PDF]</a> -->
<!-- <a href="https://ieeexplore.ieee.org/document/11027646">[PaperLink]</a> -->
<a href="https://github.com/Shixiang02/Attention-driven-RGB-D-salient-object-detection-based-on-diffusion-model">[Code]</a>
</div>

<br></br>

		
<div class="publication">
<strong>
Noise-Aware Intermediary Fusion Network for Off-Road Freespace Detection
</strong>
<br>
Ying Lv, Zhi Liu, <b>Gongyang Li</b>, Xiaojun Chang
</br>
<em>IEEE Transactions on Intelligent Vehicles (<b>TIV</b>)</em>, 2024.
<br>
<!-- <a href="./PDF/2024_TMM_LvYing.pdf">[PDF]</a> -->
<a href="https://ieeexplore.ieee.org/document/10517638">[PaperLink]</a>
<!-- <a href="https://arxiv.org/abs/2401.01624">[Arxiv]</a> -->
<a href="https://github.com/YingLv1106/NAIFNet">[Code]</a>
</div>



<!-- <h3><div style="color:#58ACFA">2025</h3> -->
<h3 style="border-bottom: 2px solid; font-size: 22px; color:#58ACFA">2025</h3></p>	

<div class="publication">
<strong>
Ordered Cross-Scale Interaction Network for No-Service Rail Surface Defect Segmentation
</strong>
<br>
<b>Gongyang Li</b>, Xiaofei Zhou, Hongyun Li
</br>
<em>IEEE Transactions on Instrumentation and Measurement (<b>TIM</b>)</em>, vol. 74, Art no. 5033210, Jun. 2025.
<br>
<a href="./PDF/2025_TIM_Gongyang.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/11018271">[PaperLink]</a>
<!-- <a href="https://arxiv.org/abs/2306.15442">[Arxiv]</a> -->
<a href="https://github.com/MathLee/OCINet">[Code]</a>
</div>

<br></br>
	
<div class="publication">
<strong>
RGB-D Rail Surface Defect Inspection Driven by Conditional Diffusion Architecture and Frequency Knowledge
</strong>
<br>
Zhihao He, <b>Gongyang Li*</b>, Zhi Liu* (* corresponding author)
</br>
<em>IEEE Sensors Journal (<b>IEEE SJ</b>)</em>, vol. 25, no. 10, pp. 18334-18343, May 2025.
<br>
<!-- <a href="./PDF/2024_TNNLS_Yingjie.pdf">[PDF]</a> -->
<a href="https://ieeexplore.ieee.org/document/10947267">[PaperLink]</a>
<a href="https://github.com/zeroyi37/DiffRSDI">[Code]</a>
</div>

<br></br>
	
<div class="publication">
<strong>
Few-shot Fine-tuning with Auxiliary Tasks for Video Anomaly Detection
</strong>
<br>
Jing Lv, Zhi Liu*, <b>Gongyang Li*</b> (* corresponding author)
</br>
<em>Multimedia Systems (<b>MS</b>)</em>, vol. 31, Art no. 127, Feb. 2025.
<br>
<a href="./PDF/2025_MS_JingLv.pdf">[PDF]</a>
<a href="https://link.springer.com/article/10.1007/s00530-025-01706-8">[PaperLink]</a>
<!-- <a href="https://github.com/YingjieSong1/EMS">[Code]</a> -->
</div>

<br></br>

	
<div class="publication">
<strong>
Dual-Guided Video Frame Interpolation with Spatial-Temporal Global Attention
</strong>
<br>
Baojun Zhou, Xinpeng Huang, <b>Gongyang Li</b>, Chao Yang, Liquan Shen, Ping An
</br>
<em>IEEE Transactions on Multimedia (<b>TMM</b>)</em>, vol. 27, pp. 7783-7795, Aug. 2025.
<br>
<!-- <a href="./PDF/2024_TNNLS_Yingjie.pdf">[PDF]</a> -->
<a href="https://ieeexplore.ieee.org/document/11125912">[PaperLink]</a>
<!-- <a href="https://github.com/YingjieSong1/EMS">[Code]</a> -->
</div>

<br></br>
	
<div class="publication">
<strong>
Feature Quality Assessment: A Database and A Lightweight Objective Method
</strong>
<br>
Shipei Wang, Ping An, Chao Yang, <b>Gongyang Li</b>, Xinpeng Huang, Shiqi Wang
</br>
<em>IEEE Transactions on Multimedia (<b>TMM</b>)</em>, vol. 27, pp. 7314-7325, Aug. 2025.
<br>
<!-- <a href="./PDF/2024_TNNLS_Yingjie.pdf">[PDF]</a> -->
<a href="https://ieeexplore.ieee.org/document/11125899">[PaperLink]</a>
<!-- <a href="https://github.com/YingjieSong1/EMS">[Code]</a> -->
</div>

<br></br>

<div class="publication">
<strong>
MOFNet: Memory Optimization Fusion Network for Query-Focused Video Summarization
</strong>
<br>
Kaifan Zhao, Ran Ma, Min Su, Haozhe Yu, Ping An, <b>Gongyang Li</b>
</br>
<em>IEEE Sensors Journal (<b>IEEE SJ</b>)</em>, vol. 25, no. 14, pp. 27642-27652, Jul. 2025.
<br>
<!-- <a href="./PDF/2024_TNNLS_Yingjie.pdf">[PDF]</a> -->
<a href="https://ieeexplore.ieee.org/document/11027646">[PaperLink]</a>
<!-- <a href="https://github.com/zeroyi37/DiffRSDI">[Code]</a> -->
</div>

<br></br>
	
<div class="publication">
<strong>
EMS: A Large-Scale Eye Movement Dataset, Benchmark and New Model for Schizophrenia Recognition
</strong>
<br>
Yingjie Song, Zhi Liu, <b>Gongyang Li</b>, Jiawei Xie, Qiang Wu, Dan Zeng, Lihua Xu, Tianhong Zhang, Jijun Wang
</br>
<em>IEEE Transactions on Neural Networks and Learning Systems (<b>TNNLS</b>)</em>, vol. 36, no. 5, pp. 9451-9462, May 2025.
<br>
<a href="./PDF/2024_TNNLS_Yingjie.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/10645682">[PaperLink]</a>
<a href="https://github.com/YingjieSong1/EMS">[Code]</a>
</div>

<br></br>
	
<div class="publication">
<strong>
Hybrid Modeling based Semantic Segmentation of Forward-Looking Sonar Images
</strong>
<br>
Yike Wang, Zhi Liu, <b>Gongyang Li</b>, Xiaofeng Lu, Xuefeng Liu, Hongwei Zhang
</br>
<em>IEEE Journal of Oceanic Engineering (<b>IEEE JOE</b>)</em>, vol. 50, no. 1, pp. 380-393, Jan. 2025.
<br>
<!-- <a href="./PDF/2024_TNNLS_Yingjie.pdf">[PDF]</a> -->
<a href="https://ieeexplore.ieee.org/document/10753270">[PaperLink]</a>
<a href="https://github.com/kw717/HMSeg">[Code]</a>
</div>



	


<!-- <h3><div style="color:#58ACFA">2024</h3> -->
<h3 style="border-bottom: 2px solid; font-size: 22px; color:#58ACFA">2024</h3></p>


<div class="publication">
<strong>
Texture-Semantic Collaboration Network for ORSI Salient Object Detection
</strong>
<br>
<b>Gongyang Li</b>, Zhen Bai, Zhi Liu
</br>
<em>IEEE Transactions on Circuits and Systems II: Express Briefs (<b>TCAS-II</b>)</em>, vol. 71, no. 4, pp. 2464-2468, Apr. 2024.
<br>
<a href="./PDF/2024_TCASII_Gongyang.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/10319772">[PaperLink]</a>
<a href="https://arxiv.org/abs/2312.03548">[Arxiv]</a>
<a href="https://github.com/MathLee/TSCNet">[Code]</a>
</div>

<br></br>

<div class="publication">
<strong>
Light Field Salient Object Detection with Sparse Views via Complementary and Discriminative Interaction Network
</strong>
<br>
Yilei Chen#, <b>Gongyang Li#</b>, Ping An, Zhi Liu, Xinpeng Huang, Qiang Wu (# equal contribution)
</br>
<em>IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>)</em>, vol. 34, no. 2, pp. 1070-1085, Feb. 2024.
<br>
<a href="./PDF/2024_TCSVT_Yilei.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/10168184">[PaperLink]</a>
<a href="https://github.com/GilbertRC/LFSOD-CDINet">[Code]</a>
</div>

<br></br>
	
<div class="publication">
<strong>
EFDCNet: Encoding Fusion and Decoding Correction Network for RGB-D Indoor Semantic Segmentation
</strong>
<br>
Jianlin Chen, <b>Gongyang Li*</b>, Zhijiang Zhang*, Dan Zeng (* corresponding author)
</br>
<em>Image and Vision Computing (<b>IVC</b>)</em>, vol. 142, Art no. 104892, Feb. 2024.
<br>
<a href="./PDF/2024_IVC_Jianlin.pdf">[PDF]</a>
<a href="https://www.sciencedirect.com/science/article/pii/S0262885623002664?via%3Dihub">[PaperLink]</a>
<a href="https://github.com/Mark9010/EFDCNet">[Code]</a>
</br>
</div>

<br></br>
		
<div class="publication">
<strong>
Context-Aware Interaction Network for RGB-T Semantic Segmentation
</strong>
<br>
Ying Lv, Zhi Liu, <b>Gongyang Li</b>
</br>
<em>IEEE Transactions on Multimedia (<b>TMM</b>)</em>, vol. 26, pp. 6348-6360, Apr. 2024. <strong><font color="#FF5151"><i>ESI Highly Cited Paper</i></font></strong>
<br>
<a href="./PDF/2024_TMM_LvYing.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/10379106">[PaperLink]</a>
<a href="https://arxiv.org/abs/2401.01624">[Arxiv]</a>
<a href="https://github.com/YingLv1106/CAINet">[Code]</a>
</div>

<br></br>
	
<div class="publication">
<strong>
Audio-Visual Saliency Prediction with Multisensory Perception and Integration
</strong>
<br>
Jiawei Xie, Zhi Liu, <b>Gongyang Li</b>, Yingjie Song
</br>
<em>Image and Vision Computing (<b>IVC</b>)</em>, vol. 143, Art no. 104955, Mar. 2024.
<br>
<a href="./PDF/2024_IVC_Jiawei.pdf">[PDF]</a>
<a href="https://www.sciencedirect.com/science/article/pii/S0262885624000581">[PaperLink]</a>
<a href="https://github.com/oraclefina/MSPI">[Code]</a>
</br>
</div>

<br></br>

<div class="publication">
<strong>
Masked Feature Regeneration based Asymmetric Student-teacher Network for Anomaly Detection
</strong>
<br>
Haocheng Gu, <b>Gongyang Li</b>, Zhi Liu
</br>
<em>Multimedia Tools and Applications (<b>MTAP</b>)</em>, vol. 83, pp. 90573-90594, Feb. 2024.
<br>
<a href="./PDF/2024_MTAP_Haocheng.pdf">[PDF]</a>
<a href="https://link.springer.com/article/10.1007/s11042-024-18512-5">[PaperLink]</a>
<!-- <a href="https://github.com/oraclefina/GSGNet">[Code]</a> -->
</div>
	
<br></br>

<div class="publication">
<strong>
Global Semantic-guided Network for Saliency Prediction
</strong>
<br>
Jiawei Xie, Zhi Liu, <b>Gongyang Li</b>, Xiaofeng Lu, Tao Chen
</br>
<em>Knowledge-Based Systems (<b>KBS</b>)</em>, vol. 284, Art no. 111279, Jan. 2024.
<br>
<a href="./PDF/2024_KBS_Jiawei.pdf">[PDF]</a>
<a href="https://www.sciencedirect.com/science/article/pii/S0950705123010274?via=ihub">[PaperLink]</a>
<a href="https://github.com/oraclefina/GSGNet">[Code]</a>
</div>

	

	
<!-- <h3><div style="color:#58ACFA">2023</h3> -->
<h3 style="border-bottom: 2px solid; font-size: 22px; color:#58ACFA">2023</h3></p>	

<div class="publication">
<strong>
Salient Object Detection in Optical Remote Sensing Images Driven by Transformer
</strong>
<br>
<b>Gongyang Li</b>, Zhen Bai, Zhi Liu, Xinpeng Zhang, Haibin Ling
</br>
<em>IEEE Transactions on Image Processing (<b>TIP</b>)</em>, vol. 32, pp. 5257-5269, Sept. 2023. <strong><font color="#FF5151"><i>ESI Highly Cited Paper</i></font></strong>
<br>
<a href="./PDF/2023_TIP_Gongyang.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/10254506">[PaperLink]</a>
<a href="https://arxiv.org/abs/2309.08206">[Arxiv]</a>
<a href="https://github.com/MathLee/GeleNet">[Code]</a>
</div>

<br></br>
	
<div class="publication">
<strong>
No-Service Rail Surface Defect Segmentation via Normalized Attention and Dual-scale Interaction
</strong>
<br>
<b>Gongyang Li#</b>, Chengjun Han#, Zhi Liu (# equal contribution)
</br>
<em>IEEE Transactions on Instrumentation and Measurement (<b>TIM</b>)</em>, vol. 72, Art no. 5020310, Jul. 2023.
<br>
<a href="./PDF/2023_TIM_Gongyang.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/10177197">[PaperLink]</a>
<a href="https://arxiv.org/abs/2306.15442">[Arxiv]</a>
<a href="https://github.com/monxxcn/NaDiNet">[Code]</a>
</div>

<br></br>

<div class="publication">
<strong>
RGB-T Semantic Segmentation with Location, Activation, and Sharpening
</strong>
<br>
<b>Gongyang Li</b>, Yike Wang, Zhi Liu, Xinpeng Zhang, Dan Zeng
</br>
<em>IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>)</em>, vol. 33, no. 3, pp. 1223-1235, Mar. 2023. <strong><font color="#FF5151"><i>ESI Highly Cited Paper</i></font></strong>
<br>
<a href="./PDF/2023_TCSVT_Gongyang.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/9900351">[PaperLink]</a>
<a href="https://arxiv.org/abs/2210.14530">[Arxiv]</a>
<a href="https://github.com/MathLee/LASNet">[Code]</a>
</div>

<br></br>

<div class="publication">
<strong>
Lightweight Salient Object Detection in Optical Remote-Sensing Images via Semantic Matching and Edge Alignment
</strong>
<br>
<b>Gongyang Li</b>, Zhi Liu, Xinpeng Zhang, Weisi Lin
</br>
<em>IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>)</em>, vol. 61, Art no. 5601111, Jan. 2023. <strong><font color="#FF5151"><i>ESI Highly Cited Paper</i></font></strong>
<br>
<a href="./PDF/2023_TGRS_Gongyang.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/10015064">[PaperLink]</a>
<a href="https://arxiv.org/abs/2301.02778">[Arxiv]</a>
<a href="https://github.com/MathLee/SeaNet">[Code]</a>
</div>
	
<br></br>
	
<div class="publication">
<strong>
Adjacent Context Coordination Network for Salient Object Detection in Optical Remote Sensing Images
</strong>
<br>
<b>Gongyang Li</b>, Zhi Liu, Dan Zeng, Weisi Lin, Haibin Ling
</br>
<em>IEEE Transactions on Cybernetics (<b>TCYB</b>)</em>, vol. 53, no. 1, pp. 526-538, Jan. 2023. <strong><font color="#FF5151"><i>ESI Highly Cited Paper</i></font></strong>
<br>
<a href="./PDF/2023_TCYB_Gongyang.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/9756652">[PaperLink]</a>
<a href="https://arxiv.org/abs/2203.13664">[Arxiv]</a>
<a href="https://github.com/MathLee/ACCoNet">[Code]</a>
</div>
	
<br></br>

<div class="publication">
<strong>
SGFNet: Semantic-Guided Fusion Network for RGB-Thermal Semantic Segmentation
</strong>
<br>
Yike Wang#, <b>Gongyang Li#</b>, Zhi Liu (# equal contribution)
</br>
<em>IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>)</em>, vol. 33, no. 12, pp. 7737-7748, Dec. 2023.
<br>
<a href="./PDF/2023_TCSVT_Yike.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/10138593">[PaperLink]</a>
<a href="https://github.com/kw717/SGFNet">[Code]</a>
</div>

<br></br>
	
<div class="publication">
<strong>
Lightweight Distortion-aware Network for Salient Object Detection in Omnidirectional Images
</strong>
<br>
Mengke Huang, <b>Gongyang Li*</b>, Zhi Liu, Linchao Zhu (* corresponding author)
</br>
<em>IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>)</em>, vol. 33, no. 10, pp. 6191-6197, Oct. 2023.
<br>
<a href="./PDF/2023_TCSVT_Mengke.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/10061423">[PaperLink]</a>
<!-- <a href="https://arxiv.org/abs/2210.14530">[Arxiv]</a> -->
<a href="https://github.com/DreaMKHuang/LDNet">[Code]</a>
</div>
	
<br></br>

<div class="publication">
<strong>
Global-Local-Global Context-aware Network for Salient Object Detection in Optical Remote Sensing Images
</strong>
<br>
Zhen Bai, <b>Gongyang Li*</b>, Zhi Liu (* corresponding author)
</br>
<em>ISPRS Journal of Photogrammetry and Remote Sensing (<b>ISPRS JP&RS</b>)</em>, vol. 198, pp. 184-196, Apr. 2023.
<br>
<a href="./PDF/2023_ISPRS_ZhenBai.pdf">[PDF]</a>
<a href="https://www.sciencedirect.com/science/article/pii/S0924271623000734">[PaperLink]</a>
<!-- <a href="https://arxiv.org/abs/2112.01932">[Arxiv]</a> -->
<!-- <a href="https://github.com/bz536476/AGCNet">[Code]</a> -->
</div>

<br></br>

<div class="publication">
<strong>
Exploring Viewport Features for Semi-Supervised Saliency Prediction in Omnidirectional Images
</strong>
<br>
Mengke Huang, <b>Gongyang Li*</b>, Zhi Liu, Yong Wu, Chen Gong, Linchao Zhu, Yi Yang (* corresponding author)
</br>
<em>Image and Vision Computing (<b>IVC</b>)</em>, vol. 129, Art no. 104590, Jan. 2023.
<br>
<a href="./PDF/2023_IVC_Mengke.pdf">[PDF]</a>
<a href="https://www.sciencedirect.com/science/article/pii/S0262885622002190">[PaperLink]</a>
</br>
</div>

<br></br>

<div class="publication">
<strong>
RINet: Relative Importance-Aware Network for Fixation Prediction
</strong>
<br>
Yingjie Song, Zhi Liu, <b>Gongyang Li</b>, Dan Zeng, Tianhong Zhang, Lihua Xu, Jijun Wang
</br>
<em>IEEE Transactions on Multimedia (<b>TMM</b>)</em>, vol. 25, pp. 9263-9277, Dec. 2023.
<br>
<a href="./PDF/2023_TMM_Yingjie.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/10054110">[PaperLink]</a>
<!-- <a href="https://arxiv.org/abs/2301.02778">[Arxiv]</a> -->
<a href="https://github.com/Mango321321/RINet">[Code]</a>
</div>

<br></br>

<div class="publication">
<strong>
Spatio-Temporal Self-Attention Network for Video Saliency Prediction
</strong>
<br>
Ziqiang Wang, Zhi Liu, <b>Gongyang Li</b>, Yang Wang, Tianhong Zhang, Lihua Xu, Jijun Wang
</br>
<em>IEEE Transactions on Multimedia (<b>TMM</b>)</em>, vol. 25, pp. 1161-1174, Apr. 2023.
<br>
<a href="./PDF/2023_TMM_Ziqiang.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/9667292">[PaperLink]</a>
<a href="https://arxiv.org/abs/2108.10696">[Arxiv]</a>
<!-- <a href="https://github.com/MathLee/MCCNet">[Code]</a> -->
</div>
	
<br></br>

<div class="publication">
<strong>
Adaptive Group-wise Consistency Network for Co-saliency Detection
</strong>
<br>
Zhen Bai, Zhi Liu, <b>Gongyang Li</b>, Yang Wang
</br>
<em>IEEE Transactions on Multimedia (<b>TMM</b>)</em>, vol. 25, pp. 764-776, Mar. 2023.
<br>
<a href="./PDF/2023_TMM_ZhenBai.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/9662960">[PaperLink]</a>
<a href="https://arxiv.org/abs/2112.01932">[Arxiv]</a>
<a href="https://github.com/bz536476/AGCNet">[Code]</a>
</div>




<!-- <h3><div style="color:#58ACFA">2022</h3> -->
<h3 style="border-bottom: 2px solid; font-size: 22px; color:#58ACFA">2022</h3></p>	

<div class="publication">
<strong>
Lightweight Salient Object Detection in Optical Remote Sensing Images via Feature Correlation
</strong>
<br>
<b>Gongyang Li</b>, Zhi Liu, Zhen Bai, Weisi Lin, Haibin Ling
</br>
<em>IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>)</em>, vol. 60, Art no. 5617712, Mar. 2022. <strong><font color="#FF5151"><i>ESI Highly Cited Paper</i></font></strong>
<br>
<a href="./PDF/2022_TGRS_Gongyang2.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/9690514">[PaperLink]</a>
<a href="https://arxiv.org/abs/2201.08049">[Arxiv]</a>
<a href="https://github.com/MathLee/CorrNet">[Code]</a>
</div>

<br></br>

<div class="publication">
<strong>
Multi-Content Complementation Network for Salient Object Detection in Optical Remote Sensing Images
</strong>
<br>
<b>Gongyang Li</b>, Zhi Liu, Weisi Lin, Haibin Ling
</br>
<em>IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>)</em>, vol. 60, Art no. 5614513, Feb. 2022. <strong><font color="#FF5151"><i>ESI Highly Cited Paper</i></font></strong>
<br>
<a href="./PDF/2022_TGRS_Gongyang.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/9631225">[PaperLink]</a>
<a href="https://arxiv.org/abs/2112.01932">[Arxiv]</a>
<a href="https://github.com/MathLee/MCCNet">[Code]</a>
</div>

<br></br>

<div class="publication">
<strong>
Gaze Estimation via Modulation-based Adaptive Network with Auxiliary Self-Learning
</strong>
<br>
Yong Wu#, <b>Gongyang Li#</b>, Zhi Liu, Mengke Huang, Yang Wang (# equal contribution)
</br>
<em>IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>)</em>, vol. 32, no. 8, pp. 5510-5520, Aug. 2022.
<br>
<a href="./PDF/2022_TCSVT_YongWu.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/9717236">[PaperLink]</a>
<!-- <a href="https://arxiv.org/abs/2201.08049">[Arxiv]</a>
<a href="https://github.com/MathLee/CorrNet">[Code]</a> -->
</div>

<br></br>

<div class="publication">
<strong>
Two-Stage Edge Reuse Network for Salient Object Detection of Strip Steel Surface Defects
</strong>
<br>
Chengjun Han#, <b>Gongyang Li#</b>, Zhi Liu (# equal contribution)
</br>
<em>IEEE Transactions on Instrumentation and Measurement (<b>TIM</b>)</em>, vol. 71, Art no. 5019812, Aug. 2022.
<br>
<a href="./PDF/2022_TIM_Chengjun.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/9862999">[PaperLink]</a>
<a href="https://github.com/monxxcn/TSERNet">[Code]</a>
</div>

<br></br>

<div class="publication">
<strong>
Cross-Scale Edge Purification Network for Salient Object Detection of Steel Defect Images
</strong>
<br>
Tuo Ding#, <b>Gongyang Li#</b>, Zhi Liu, Yike Wang (# equal contribution)
</br>
<em>Measurement</em>, vol. 199, Art no. 111429, Aug. 2022.
<br>
<a href="./PDF/2022_Mea_TuoDing.pdf">[PDF]</a>
<a href="https://www.sciencedirect.com/science/article/pii/S0263224122006595?via%3Dihub">[PaperLink]</a>
<a href="https://github.com/showmaker369/CSEPNet">[Code]</a>
</div>

<br></br>

<div class="publication">
<strong>
适于少样本缺陷检测的两阶段缺陷增强网络
</strong>
<br>
陈朝, 刘志, <b>李恭杨</b>, 彭铁根
</br>
<em>计算机工程与应用</em>, vol. 58, no. 20, pp. 108-116, 2022.
<br>
<a href="./PDF/2022_ZhaoChen.pdf">[PDF]</a>
<a href="http://cea.ceaj.org/CN/10.3778/j.issn.1002-8331.2111-0470">[PaperLink]</a>
<!-- <a href="https://github.com/showmaker369/CSEPNet">[Code]</a> -->
</div>


<!-- <h3><div style="color:#58ACFA">2021</h3> -->
<h3 style="border-bottom: 2px solid; font-size: 22px; color:#58ACFA">2021</h3></p>
	
<div class="publication">
<strong>
Hierarchical Alternate Interaction Network for RGB-D Salient Object Detection
</strong>
<br>
<b>Gongyang Li</b>, Zhi Liu, Minyu Chen, Zhen Bai, Weisi Lin, Haibin Ling
</br>
<em>IEEE Transactions on Image Processing (<b>TIP</b>)</em>, vol. 30, pp. 3528-3542, Mar. 2021. <strong><font color="#FF5151"><i>ESI Highly Cited Paper</i></font></strong>
<br>
<a href="./PDF/2021_TIP_Gongyang.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/9371407">[PaperLink]</a>
<a href="https://github.com/MathLee/HAINet">[Code]</a>
</div>

<br></br>

<div class="publication">
<strong>
Personal Fixations-based Object Segmentation with Object Localization and Boundary Preservation
</strong>
<br>
<b>Gongyang Li</b>, Zhi Liu, Ran Shi, Zheng Hu, Weijie Wei, Yong Wu, Mengke Huang, Haibin Ling
</br>
<em>IEEE Transactions on Image Processing (<b>TIP</b>)</em>, vol. 30, pp. 1461-1475, Jan. 2021.
<br>
<a href="./PDF/2021_TIP_Gongyang2.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/9298925">[PaperLink]</a>
<a href="https://arxiv.org/abs/2101.09014">[Arxiv]</a>
<a href="https://github.com/MathLee/OLBPNet4PFOS">[Code]</a>
</div>

<br></br>

<div class="publication">
<strong>
Circular Complement Network for RGB-D Salient Object Detection
</strong>
<br>
Zhen Bai, Zhi Liu, <b>Gongyang Li</b>, Linwei Ye, Yang Wang
</br>
<em>Neurocomputing</em>, vol. 451, pp. 95-106, Sept. 2021.
<br>
<a href="./PDF/2021_NC_ZhenBai.pdf">[PDF]</a>
<a href="https://www.sciencedirect.com/science/article/pii/S0925231221005944">[PaperLink]</a>
<a href="https://github.com/bz536476/CCNet">[Code]</a>
</div>

<br></br>

<div class="publication">
<strong>
Personalized Image Observation Behavior Learning in Fixation based Personalized Salient Object Segmentation
</strong>
<br>
Ran Shi, <b>Gongyang Li</b>, Weijie Wei, Xiaofei Zhou, Zhi Liu
</br>
<em>Neurocomputing</em>, vol. 445, pp. 255-266, Jul. 2021.
<br>
<a href="./PDF/2021_NC_RanShi.pdf">[PDF]</a>
<a href="https://www.sciencedirect.com/science/article/pii/S0925231221004100">[PaperLink]</a>
</div>

<br></br>

<div class="publication">
<strong>
Fixations based Personal Target Objects Segmentation
</strong>
<br>
Ran Shi, <b>Gongyang Li</b>, Weijie Wei, Zhi Liu
</br>
<em>ACM International Conference on Multimedia in Asia (<b>MMAsia 2020</b>)</em>, Singapore, Mar. 2021.
<br>
<a href="./PDF/2020_MMAsia_RanShi.pdf">[PDF]</a>
<a href="https://dl.acm.org/doi/pdf/10.1145/3444685.3446310">[PaperLink]</a>
</br>
</div>


<!-- <h3><div style="color:#58ACFA">2020</h3> -->
<h3 style="border-bottom: 2px solid; font-size: 22px; color:#58ACFA">2020</h3></p>
	
<div class="publication">
<strong>
ICNet: Information Conversion Network for RGB-D based Salient Object Detection
</strong>
<br>
<b>Gongyang Li</b>, Zhi Liu, Haibin Ling
</br>
<em>IEEE Transactions on Image Processing (<b>TIP</b>)</em>, vol. 29, pp. 4873-4884, Mar. 2020. <strong><font color="#FF5151"><i>ESI Highly Cited Paper</i></font></strong>
<br>
<a href="./PDF/2020_TIP_Gongyang.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/9024241">[PaperLink]</a>
<a href="https://github.com/MathLee/ICNet-for-RGBD-SOD">[Code]</a>
</div>

<br></br>

<div class="publication">
<strong>
Cross-Modal Weighting Network for RGB-D Salient Object Detection
</strong>
<br>
<b>Gongyang Li</b>, Zhi Liu, Linwei Ye, Yang Wang, Haibin Ling
</br>
<em>European Conference on Computer Vision (<b>ECCV</b>)</em>, pp. 665-681, Glasgow, UK, Aug. 2020.
<br>
<a href="./PDF/2020_ECCV_Gongyang.pdf">[PDF]</a>
<a href="https://link.springer.com/chapter/10.1007/978-3-030-58520-4_39">[PaperLink]</a>
<a href="https://arxiv.org/abs/2007.04901">[Arxiv]</a>
<a href="https://github.com/MathLee/CMWNet">[Code]</a>
</div>
	
<br></br>

<div class="publication">
<strong>
Attention-guided RGBD Saliency Detection using Appearance Information
</strong>
<br>
Xiaofei Zhou, <b>Gongyang Li</b>, Chen Gong, Zhi Liu, Jiyong Zhang
</br>
<em>Image and Vision Computing (<b>IVC</b>)</em>, vol. 95, Art no. 103888, Mar. 2020.
<br>
<a href="./PDF/2020_IVC_Xiaofei.pdf">[PDF]</a>
<a href="https://www.sciencedirect.com/science/article/pii/S0262885620300202">[PaperLink]</a>
</br>
</div>

<br></br>

<div class="publication">
<strong>
FANet: Features Adaptation Network for 360° Omnidirectional Salient Object Detection
</strong>
<br>
Mengke Huang, Zhi Liu, <b>Gongyang Li</b>, Xiaofei Zhou, Olivier Le Meur
</br>
<em>IEEE Signal Processing Letters (<b>SPL</b>)</em>, vol. 27, pp. 1819-1823, Oct. 2020.
<br>
<a href="./PDF/2020_SPL_Mengke.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/9211754">[PaperLink]</a>
<a href="https://github.com/DreaMKHuang/FANet">[Code]</a>
</br>
</div>

<br></br>

<div class="publication">
<strong>
Weakly Supervised Instance Segmentation using Multi-stage Erasing Refinement and Saliency-guided Proposals Ordering
</strong>
<br>
Zheng Hu, Zhi Liu, <b>Gongyang Li</b>, Linwei Ye, Lei Zhou, Yang Wang
</br>
<em>Journal of Visual Communication and Image Representation (<b>JVCI</b>)</em>, vol. 73, Art no. 102957, Nov. 2020.
<br>
<a href="./PDF/2020_JVCI_ZhengHu.pdf">[PDF]</a>
<a href="https://www.sciencedirect.com/science/article/pii/S104732032030184X">[PaperLink]</a>
<a href="https://github.com/jetshz/MSER-SGPO">[Code]</a>
</br>
</div>

<br></br>

<div class="publication">
<strong>
Co-Saliency Detection using Collaborative Feature Extraction and High-to-Low Feature Integration
</strong>
<br>
Jingru Ren, Zhi Liu, <b>Gongyang Li</b>, Xiaofei Zhou, Cong Bai, Guangling Sun
</br>
<em>IEEE International Conference on Multimedia and Expo (<b>ICME</b>)</em>, London, UK, Jul. 2020.
<br>
<a href="./PDF/2020_ICME_Jingru.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/9102969">[PaperLink]</a>
<a href="https://pan.baidu.com/share/init?surl=RofTzQ07Vi-GRohnmSy7pg">[Results (code: 180w)]</a>
</br>
</div>

<br></br>

<div class="publication">
<strong>
Fine-grained Image Classification with Coarse and Fine Labels on One-shot Learning
</strong>
<br>
Qihan Jiao, Zhi Liu, <b>Gongyang Li</b>, Linwei Ye, Yang Wang
</br>
<em>IEEE International Conference on Multimedia and Expo Workshops (<b>ICMEW</b>)</em>, London, UK, Jul. 2020.
<br>
<a href="./PDF/2020_ICMEW_Qihan.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/9105959">[PaperLink]</a>
<a href="https://pan.baidu.com/share/init?surl=8j5sa8WITcRzWDoSathT8g">[Results (code: mkY7)]</a>
</br>
</div>


<!-- <h3><div style="color:#58ACFA">2019 and Before</h3> -->
<h3 style="border-bottom: 2px solid; font-size: 22px; color:#58ACFA">2019 and Before</h3></p>

<div class="publication">
<strong>
Constrained Fixation Point based Segmentation via Deep Neural Network
</strong>
<br>
<b>Gongyang Li</b>, Zhi Liu, Ran Shi, Weijie Wei
</br>
<em>Neurocomputing</em>, vol. 368, pp. 180-187, Nov. 2019.
<br>
<a href="./PDF/2019_NC_Gongyang.pdf">[PDF]</a>
<a href="https://www.sciencedirect.com/science/article/pii/S0925231219311890">[PaperLink]</a>
<a href="https://github.com/MathLee/CFPS">[Code]</a>
</br>
</div>

<br></br>

<div class="publication">
<strong>
Effective Online Refinement for Video Object Segmentation
</strong>
<br>
<b>Gongyang Li</b>, Zhi Liu, Xiaofei Zhou
</br>
<em>Multimedia Tools and Applications (<b>MTAP</b>)</em>, vol. 78, pp. 33617-33631, Sept. 2019.
<br>
<a href="./PDF/2019_MTAP_Gongyang.pdf">[PDF]</a>
<a href="https://link.springer.com/article/10.1007/s11042-019-08146-3">[PaperLink]</a>
<a href="https://github.com/MathLee/EOR-VOS">[Code]</a>
</br>
</div>

<br></br>

<div class="publication">
<strong>
Video Saliency Detection using Deep Convolutional Neural Networks
</strong>
<br>
Xiaofei Zhou, Zhi Liu, Chen Gong, <b>Gongyang Li</b>, Mengke Huang
</br>
<em>Chinese Conference on Pattern Recognition on Computer Vision (<b>PRCV</b>)</em>, pp. 308-319, Guangzhou, China, Nov. 2018.
<br>
<a href="./PDF/2019_PRCV_Xiaofei.pdf">[PDF]</a>
<a href="https://link.springer.com/chapter/10.1007%2F978-3-030-03335-4_27">[PaperLink]</a>
</br>
</div>

<br></br>



<!--<p style="text-align:center;font-size:16px;padding-top:20px;">All things are difficult before they are easy.-->
<!--<br>&mdash; Thomas Fuller</p>-->

<br clear="both">
<br>
<br>
<br>
<br>
<br>
<br>
<button type="button"><span id="scrolltop" onclick="window.scrollTo(&#39;0&#39;,&#39;0&#39;)">Back to TOP</span></button>

</div>
</div>

</body>
</html>

