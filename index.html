<html>
<head>
<title>GONGYANG LI</title>
<style>
h1 { padding : 0; margin : 0; }
body { padding : 0; font-family : Arial; font-size : 16px;  background-color : #EFEFEF;} /* background-image : url('bg.png');}*/
#container { width : 900px; margin : 20px auto; border-radius: 15px;  background-color : #fff; padding : 50px;  box-shadow: 0px 0px 10px #999; } /* border : 1px solid #ccc; } */
#me { border : 0 solid black; margin-bottom : 50px;}
#sidebar { margin-left : 25px; border : 0 solid black; float : right; margin-bottom : 0;}
#content { display : block; }
a { text-decoration : none; }
a:hover { text-decoration : underline; }
a, a:visited { color : #0050e7; }
a.invisible { color : inherit; text-decoration : inherit; }
.publogo { margin-right : 20px; float : left; border : 0;}
.publication { clear : left; padding-bottom : 0px; }
.publication p { height : 100px; padding-top : 5px;}
.publication strong a { color : #000; }
.publication .links { position : relative; top : 15px }
.publication .links a { margin-right : 20px; }
.codelogo { margin-right : 10px; float : left; border : 0;}
.code { clear : left; padding-bottom : 10px; vertical-align :middle;} 
.code .download a { display : block; margin : 0 15px; float : left;}
.code strong a { color : #000; }
#simpsons { margin : 5px auto; text-align : left; color : #B7B7B7; }
#erdos { color : #999; text-align : center; font-size : 12px; }
.contact { margin-left : 40px; }
.contact td { width : 300px; vertical-align : top; }
.schoollogo { text-align : center; color : #999; width : 150px;}
.schoollogo img { margin-bottom : 10px; }
</style>

<script type="text/javascript">

var _gaq = _gaq || [];
_gaq.push(['_setAccount', 'UA-17813713-3']);
_gaq.push(['_setDomainName', '.mit.edu']);
_gaq.push(['_trackPageview']);

(function() {
var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})();

</script>


<body>
<div id="container">
<div id="content">
<div id="sidebar">
<a href="lgy.jpg"><img src="./lgy.jpg" id="me" itemprop="photo"></a>
</div>

<tr>
<td itemprop="address">
<br>
Gongyang LI
<a href="./cv_ligongyang.pdf">[CV]</a>
<br>
Postdoc
<br>
<a href="https://www.ivp.shu.edu.cn/" target="blank" style="color:#58ACFA">Image and Video Processing Lab</a>
<br>
School of Communication and Information Engineering
<br>
Shanghai University
<br>
Shanghai, China
<br>
Email: ligongyang [at] shu [dot] edu [dot] cn
<br>
</td>
</tr>

<h3>
[<a href="https://mathlee.github.io/" style="color:#58ACFA">Main</a>]
[<a href="Publication.html" style="color:#58ACFA">Publication</a>] 
[<a href="https://scholar.google.com/citations?hl=zh-CN&user=YNq7jc8AAAAJ" target="blank" style="color:#58ACFA">Google Scholar</a>]
[<a href="https://github.com/mathlee" target="blank" style="color:#58ACFA">Code & Data</a>]
</h3>

<h3><div style="color:#58ACFA">Education</h3>
<div class="Education">
Shanghai University, China (Jun. 2022 - Now)
<br>
<li>Postdoc</li>
<li>Supervisor: Prof. <a href="https://scie.shu.edu.cn/Prof/zhangxp.htm" target="_blank" rel="external">Xinpeng Zhang</a> and Prof. <a href="https://www.ivp.shu.edu.cn/Default.aspx?tabid=31916" target="_blank" rel="external">Zhi Liu</a></li>
</div>
	
<div class="Education">
<br>
Nanyang Technological University, Singapore (Jul. 2021 - Jun. 2022)
<br>
<li>Visiting Ph.D. Student, Media & Interactive Computing Lab (MICL-CVL)</li>
<li>Advisor: Prof. <a href="https://personal.ntu.edu.sg/wslin/" target="_blank" rel="external">Weisi Lin</a></li>
</div>
	
<div class="Education">
<br>
Shanghai University, China (Sep. 2016 - Jun. 2022)
<br>
<!-- <li> Doctor of Philosophy (Ph.D.), Signal and Information Processing</li> -->
<li>Ph.D., Signal and Information Processing</li>
<li>Successive Master-Doctor Program</li>
<li>Advisor: Prof. <a href="https://www.ivp.shu.edu.cn/Default.aspx?tabid=31916" target="_blank" rel="external">Zhi Liu</a></li>
</div>

<h3><div style="color:red">News</div></h3>
<li> 2023.01: A paper on Lightweight SOD in Optical Remote Sensing Images (ORSI-SOD) named SeaNet accepted by TGRS.</li>

<li> 2022.11: A paper on Semi-Supervised Saliency Prediction in Omnidirectional Images (<a href="./PDF/2023_IVC_Mengke.pdf">pdf</a>) accepted by IVC. Congratulations to Mengke!</li>
<li> 2022.11: One paper HAINet (<a href="./PDF/2021_TIP_Gongyang.pdf"/>pdf</a>) has been newly selected as <strong><font><i>ESI Highly Cited Paper</i></font></strong>.</li>
<li> 2022.09: A paper on RGB-T Semantic Segmentation (<a href="./PDF/2022_TCSVT_Gongyang.pdf">pdf</a>) accepted by TCSVT.</li>
<li> 2022.08: A paper on SOD of Strip Steel Defect Images (SDI-SOD) (<a href="./PDF/2022_TIM_Chengjun.pdf">pdf</a>) accepted by TIM. Congratulations to Chengjun!</li>
<li> 2022.06: I successfully defended my PhD thesis, congratulations!</li>
<li> 2022.05: A paper on SOD of Steel Defect Images (SDI-SOD) (<a href="./PDF/2022_Mea_TuoDing.pdf">pdf</a>) accepted by Measurement. Congratulations to Tuo Ding!</li>
<li> 2022.05: One paper ICNet (<a href="./PDF/2020_TIP_Gongyang.pdf">pdf</a>) has been newly selected as <strong><font><i>ESI Highly Cited Paper</i></font></strong>.</li>
<li> 2022.03: A paper on SOD in Optical Remote Sensing Images (ORSI-SOD) (<a href="./PDF/2023_TCYB_Gongyang.pdf">pdf</a>) accepted by TCYB.</li>
<li> 2022.02: A paper on Gaze Estimation (<a href="./PDF/2022_TCSVT_YongWu.pdf">pdf</a>) accepted by TCSVT. Congratulations to Yong Wu!</li>
<li> 2022.01: A paper on Lightweight SOD in Optical Remote Sensing Images (ORSI-SOD) (<a href="./PDF/2022_TGRS_Gongyang2.pdf">pdf</a>) accepted by TGRS.</li>

<!-- <li> 2021.12: A paper on Video Saliency Prediction (VSP) (<a href="https://arxiv.org/abs/2108.10696">pdf</a>) accepted by TMM. Congratulations to Ziqiang Wang!</li>
<li> 2021.11: A paper on SOD in Optical Remote Sensing Images (ORSI-SOD) (<a href="https://ieeexplore.ieee.org/document/9631225">pdf</a>) accepted by TGRS.</li>
<li> 2021.11: A paper on Co-saliency Detection (<a href="https://ieeexplore.ieee.org/document/9662960">pdf</a>) accepted by TMM. Congratulations to Zhen Bai!</li>
<li> 2021.02: A paper on RGB-D Salient Object Detection accepted (<a href="https://ieeexplore.ieee.org/document/9371407">pdf</a>) by TIP.</li> -->

<!--<li> <a style="color:red">Call for papers</a>! Special Issue of <a href="https://www.mdpi.com/journal/symmetry/special_issues/Image_Processing_Symmetry_Topics_Applications" -->
<!--								       target="blank">"Image Processing and Symmetry: Topics and Applications"</a> in the journal <a style="color:blue">Symmetry</a>.</li> -->

<!-- 
<h3><div style="color:#58ACFA">Education</div></h3>
<li>2021.07--Now: Visiting Ph.D. Student, School of Computer Science and Engineering, Nanyang Technological University.</li>
<li>2016.09--Now: M.Sc. & Ph.D. Student, School of Communication and Information Engineering, Shanghai University.</li> -->
	
<h3><div style="color:#58ACFA">Research Interests</div></h3>
Computer Vision: Saliency Detection, Multi-modal Processing, Image/Video Object Segmentation, Semantic Segmentation
<br>


<h3><div style="color:#58ACFA">Recently accepted</h3>

<div class="publication">
<strong>
Lightweight Salient Object Detection in Optical Remote Sensing Images via Semantic Matching and Edge Alignment
</strong>
<br>
<b>Gongyang Li</b>, Zhi Liu, Xinpeng Zhang, Weisi Lin
</br>
<em>IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>)</em>, 2023.
<br>
<!-- <a href="./PDF/">[PDF]</a> -->
<!-- <a href="https://ieeexplore.ieee.org/document/9756652">[PaperLink]</a> -->
<a href="https://arxiv.org/abs/2301.02778">[Arxiv]</a>
<a href="https://github.com/MathLee/SeaNet">[Code]</a>
</div>
	
<br></br>
	
<div class="publication">
<strong>
Adjacent Context Coordination Network for Salient Object Detection in Optical Remote Sensing Images
</strong>
<br>
<b>Gongyang Li</b>, Zhi Liu, Dan Zeng, Weisi Lin, Haibin Ling
</br>
<em>IEEE Transactions on Cybernetics (<b>TCYB</b>)</em>, vol. 53, no. 1, pp. 526-538, 2023.
<br>
<a href="./PDF/2023_TCYB_Gongyang.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/9756652">[PaperLink]</a>
<a href="https://arxiv.org/abs/2203.13664">[Arxiv]</a>
<a href="https://github.com/MathLee/ACCoNet">[Code]</a>
</div>
	
<br></br>

<div class="publication">
<strong>
RGB-T Semantic Segmentation with Location, Activation, and Sharpening
</strong>
<br>
<b>Gongyang Li</b>, Yike Wang, Zhi Liu, Xinpeng Zhang, Dan Zeng
</br>
<em>IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>)</em>, 2022.
<br>
<a href="./PDF/2022_TCSVT_Gongyang.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/9900351">[PaperLink]</a>
<a href="https://arxiv.org/abs/2210.14530">[Arxiv]</a>
<a href="https://github.com/MathLee/LASNet">[Code]</a>
</div>

<br></br>
	
<div class="publication">
<strong>
Two-Stage Edge Reuse Network for Salient Object Detection of Strip Steel Surface Defects
</strong>
<br>
Chengjun Han#, <b>Gongyang Li#</b>, Zhi Liu (# equal contribution)
</br>
<em>IEEE Transactions on Instrumentation and Measurement (<b>TIM</b>)</em>, vol. 71, Art no. 5019812, 2022.
<br>
<a href="./PDF/2022_TIM_Chengjun.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/9862999">[PaperLink]</a>
<a href="https://github.com/monxxcn/TSERNet">[Code]</a>
</div>

<br></br>
	
<div class="publication">
<strong>
Cross-Scale Edge Purification Network for Salient Object Detection of Steel Defect Images
</strong>
<br>
Tuo Ding#, <b>Gongyang Li#</b>, Zhi Liu, Yike Wang (# equal contribution)
</br>
<em>Measurement</em>, vol. 199, Art no. 111429, 2022.
<br>
<a href="./PDF/2022_Mea_TuoDing.pdf">[PDF]</a>
<a href="https://www.sciencedirect.com/science/article/pii/S0263224122006595?via%3Dihub">[PaperLink]</a>
<a href="https://github.com/showmaker369/CSEPNet">[Code]</a>
</div>

<br></br>
	
<div class="publication">
<strong>
Gaze Estimation via Modulation-based Adaptive Network with Auxiliary Self-Learning
</strong>
<br>
Yong Wu#, <b>Gongyang Li#</b>, Zhi Liu, Mengke Huang, Yang Wang (# equal contribution)
</br>
<em>IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>)</em>, vol. 32, no. 8, pp. 5510-5520, 2022.
<br>
<a href="./PDF/2022_TCSVT_YongWu.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/9717236">[PaperLink]</a>
<!-- <a href="https://arxiv.org/abs/2201.08049">[Arxiv]</a> -->
<!-- <a href="https://github.com/MathLee/CorrNet">[Code]</a> -->
</div>

<br></br>

<div class="publication">
<strong>
Lightweight Salient Object Detection in Optical Remote Sensing Images via Feature Correlation
</strong>
<br>
<b>Gongyang Li</b>, Zhi Liu, Zhen Bai, Weisi Lin, Haibin Ling
</br>
<em>IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>)</em>, vol. 60, Art no. 5617712, 2022.
<br>
<a href="./PDF/2022_TGRS_Gongyang2.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/9690514">[PaperLink]</a>
<a href="https://arxiv.org/abs/2201.08049">[Arxiv]</a>
<a href="https://github.com/MathLee/CorrNet">[Code]</a>
</div>

<br></br>
	
<div class="publication">
<strong>
Multi-Content Complementation Network for Salient Object Detection in Optical Remote Sensing Images
</strong>
<br>
<b>Gongyang Li</b>, Zhi Liu, Weisi Lin, Haibin Ling
</br>
<em>IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>)</em>, vol. 60, Art no. 5614513, 2022.
<br>
<a href="./PDF/2022_TGRS_Gongyang.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/9631225">[PaperLink]</a>
<a href="https://arxiv.org/abs/2112.01932">[Arxiv]</a>
<a href="https://github.com/MathLee/MCCNet">[Code]</a>
</div>

<br></br>

<div class="publication">
<strong>
Adaptive Group-wise Consistency Network for Co-saliency Detection
</strong>
<br>
Zhen Bai, Zhi Liu, <b>Gongyang Li</b>, Yang Wang
</br>
<em>IEEE Transactions on Multimedia (<b>TMM</b>)</em>, 2021.
<br>
<a href="./PDF/2021_TMM_ZhenBai.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/9662960">[PaperLink]</a>
<a href="https://arxiv.org/abs/2112.01932">[Arxiv]</a>
<a href="https://github.com/bz536476/AGCNet">[Code]</a>
</div>

<br></br>
	
<div class="publication">
<strong>
Spatio-Temporal Self-Attention Network for Video Saliency Prediction
</strong>
<br>
Ziqiang Wang, Zhi Liu, <b>Gongyang Li</b>, Yang Wang, Tianhong Zhang, Lihua Xu, Jijun Wang
</br>
<em>IEEE Transactions on Multimedia (<b>TMM</b>)</em>, 2021.
<br>
<a href="./PDF/2021_TMM_Ziqiang.pdf">[PDF]</a>
<a href="https://ieeexplore.ieee.org/document/9667292">[PaperLink]</a>
<a href="https://arxiv.org/abs/2108.10696">[Arxiv]</a>
<!-- <a href="https://github.com/MathLee/MCCNet">[Code]</a> -->
</div>




<!--<p style="text-align:center;font-size:16px;padding-top:20px;">All things are difficult before they are easy.-->
<!--<br>&mdash; Thomas Fuller</p>-->

<br clear="both">
<br>
<br>
<br>
<br>
<br>
<br>
<button type="button"><span id="scrolltop" onclick="window.scrollTo(&#39;0&#39;,&#39;0&#39;)">Back to TOP</span></button>

</div>
</div>

</body>
</html>

